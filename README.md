Production-ready AI-powered assessment platform with real-time timer, adaptive questions, and comprehensive performance analytics.

## ğŸŒŸ Key Features

### ğŸ¯ **Core Assessment System**
- **ï¿½ 20 Questions** - Multiple choice format with adaptive generation
- **â±ï¸ Real-time Timer** - JavaScript countdown with color-coded warnings
- **ï¿½ Performance Analytics** - Comprehensive results and recommendations
- **ğŸ¤– AI-Powered Questions** - Dynamic generation with multiple LLM providers
- **ğŸ“· Basic Camera** - Simple visual monitoring (320x240px)

### ğŸ”§ **Multi-LLM Support**
- **ğŸ¤– Google Gemini** - Primary AI provider with fallback options
- **ğŸ¦¾ Groq** - Fast responses with llama models
- **ğŸŒ OpenRouter** - Multiple model access
- **ğŸ” Perplexity** - Advanced reasoning capabilities
- **ğŸ”„ Automatic Fallback** - Seamless API switching on quota issues

### ï¿½ **User Experience**
- **ğŸ‘¤ Professional Registration** - Clean user onboarding
- **ğŸ“‹ Enhanced Rules** - Clear assessment guidelines
- **ğŸ¨ Modern UI** - Professional design with smooth transitions
- **ğŸ“± Responsive** - Works on all devices
- **âš¡ Fast Performance** - Optimized for speed

## ğŸ› ï¸ Technology Stack

- **Frontend**: Streamlit 1.28.1
- **Backend**: Python 3.8+
- **AI Models**: Gemini, Groq, OpenRouter, Perplexity
- **Data Storage**: JSON files with structured results
- **Camera**: Streamlit st.camera_input with CSS positioning
- **Timer**: JavaScript with real-time updates
- **Environment**: Cross-platform compatible

## ğŸ“¦ Installation

### 1. **Clone the Repository**
```bash
git clone https://github.com/kamlesh9876/Assement-Test.git
cd Assement-Test
```

### 2. **Install Dependencies**
```bash
pip install -r requirements.txt
```

### 3. **Set Up Environment Variables**
```bash
cp .env.example .env
# Edit .env with your API keys
```

### 4. **Run the Application**
```bash
streamlit run app.py
```

## ğŸ”§ Configuration

### API Keys Required
Add the following to your `.env` file:

```env
# Primary Gemini API Key
GEMINI_API_KEY=your_gemini_api_key

# Backup Gemini Keys (optional but recommended)
GEMINI_API_KEY_1=your_second_gemini_key
GEMINI_API_KEY_2=your_third_gemini_key

# Other AI Providers
GROQ_API_KEY=your_groq_api_key
OPENROUTER_API_KEY=your_openrouter_api_key
PERPLEXITY_API_KEY=your_perplexity_api_key
```

### Free API Keys Setup
- **Gemini**: Get from [Google AI Studio](https://makersuite.google.com/app/apikey)
- **Groq**: Get from [Groq Console](https://console.groq.com/keys)
- **OpenRouter**: Get from [OpenRouter](https://openrouter.ai/keys)
- **Perplexity**: Get from [Perplexity](https://www.perplexity.ai/settings/api)

## ğŸ¯ Usage

### Assessment Flow
1. **ğŸ‘¤ Registration** - Fill in candidate details (name, university, programming language, difficulty)
2. **ğŸ“‹ Rules** - Review and accept assessment guidelines
3. **ğŸ§  Assessment** - Complete 20 questions with real-time timer
   - Live countdown timer with color warnings
   - Basic camera monitoring
   - Performance tracking
4. **ğŸ“Š Results** - View comprehensive analysis with AI insights

### Key Features During Assessment
- **â±ï¸ Real-time Timer** - Counts down with visual warnings (green â†’ orange â†’ red)
- **ğŸ“Š Live Progress** - Question tracking and completion status
- **ğŸ“· Camera Monitoring** - Basic visual monitoring in corner
- **ğŸ¯ Performance Metrics** - Real-time score calculation

## ğŸ”„ API Management System

### Automatic Quota Handling
The system automatically manages API quotas:

1. **Priority Order**: Groq â†’ OpenRouter â†’ Perplexity â†’ Gemini
2. **Auto-Rotation**: Switches APIs when quota exceeded
3. **Key Rotation**: Multiple Gemini keys for redundancy
4. **Graceful Fallback**: Uses default questions if all APIs fail

## ğŸ“ Project Structure

```
â”œâ”€â”€ app.py                    # Main Streamlit application
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example             # Environment variables template
â”œâ”€â”€ README.md                # This documentation
â”œâ”€â”€ TODO.txt                 # Future integration roadmap
â”œâ”€â”€ data/                    # Data storage
â”‚   â”œâ”€â”€ results/             # Assessment results
â”‚   â””â”€â”€ knowledge_base/     # Reference materials
â”œâ”€â”€ integrated_assessment.py # Active assessment system
â”œâ”€â”€ adaptive_agent.py        # Active AI question generation
â”œâ”€â”€ advanced_proctoring.py   # Available for future integration
â”œâ”€â”€ analytics_dashboard.py   # Available for future integration
â”œâ”€â”€ computer_vision.py       # Available for future integration
â”œâ”€â”€ conversational_ai.py     # Available for future integration
â””â”€â”€ emotional_intelligence.py # Available for future integration
```

## ğŸš€ Deployment

### Local Development
```bash
streamlit run app.py
```

### Production Deployment
```bash
# Using Streamlit Cloud
streamlit run app.py --server.headless=true

# Using Docker
docker build -t nelumbus-assessment .
docker run -p 8501:8501 nelumbus-assessment
```

## ğŸ”’ Security Features

- **Environment Variables**: Secure API key storage
- **Session Isolation**: User data privacy protection
- **Input Validation**: Prevents malicious input
- **Camera Control**: User consent and privacy controls
- **Error Handling**: No sensitive data exposure

## ğŸ“ˆ Performance Features

- **âš¡ Fast Loading**: Optimized asset delivery
- **ğŸ’¾ Smart Caching**: Reduces API calls with hint caching
- **ğŸ”„ API Rotation**: Automatic load balancing
- **ğŸ“± Responsive Design**: Works on all devices
- **ğŸ›¡ï¸ Error Recovery**: Graceful degradation

##  Troubleshooting

### Common Issues

#### "API quota exceeded" Message
**Solution**: 
1. Wait for quota reset (usually 1 hour for free tiers)
2. Add backup API keys to `.env` file
3. Use multiple API providers for redundancy

#### Timer Not Working
**Solution**:
1. Ensure JavaScript is enabled in browser
2. Check browser console for errors
3. Refresh page and restart assessment

#### Questions Not Generating
**Solution**:
1. Check if API keys are correctly configured
2. Verify internet connection
3. System will fallback to default questions if APIs fail

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ†˜ Support

For issues and questions:
- ğŸ› Create an issue on GitHub
- ğŸ“§ Check the troubleshooting section
- ï¿½ Review TODO.txt for planned features

## ğŸ”„ Version History

- **v2.1.0**: Optimized Production Release
  - Simplified agent system (7 â†’ 2 active agents)
  - Real-time JavaScript timer implementation
  - Enhanced assessment rules with professional UI
  - Comprehensive TODO.txt for future development
  - Code optimization (40% reduction in complexity)

- **v2.0.0**: Complete agentic assessment system
  - Added AI-powered user context tracking
  - Integrated corner camera monitoring
  - Implemented smart API quota management
  - Enhanced performance analytics

- **v1.3.0**: Improved error handling and fallback system
- **v1.2.0**: Enhanced UI/UX design
- **v1.1.0**: Added multi-LLM support
- **v1.0.0**: Initial release with basic assessment functionality

## ğŸ¯ Current Status

**âœ… Production Ready**: Core functionality fully operational
**ğŸš€ Deployable**: Ready for production deployment
**ğŸ“Š Optimized**: Simplified and maintainable codebase
**ğŸ”® Future Roadmap**: Documented in TODO.txt

---

**Built with â¤ï¸ for modern AI-powered assessment needs**

ğŸŒŸ **Status**: Production Ready & Optimized
ğŸ”— **Repository**: https://github.com/kamlesh9876/Assement-Test
ï¿½ **Access**: http://localhost:8501
